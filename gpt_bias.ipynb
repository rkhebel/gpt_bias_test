{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama, LogitsProcessorList, LogitsProcessor\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model comparisons later\n",
    "models = [\n",
    "    {\n",
    "        'repo_id': 'bartowski/Llama-3.2-1B-Instruct-GGUF',\n",
    "        'filename': 'Llama-3.2-1B-Instruct-Q4_K_M.gguf',\n",
    "    },\n",
    "    {\n",
    "        'repo_id': 'bartowski/Llama-3.2-3B-Instruct-GGUF',\n",
    "        'filename': 'Llama-3.2-3B-Instruct-Q4_K_M.gguf',\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama.from_pretrained(\n",
    "    repo_id = 'bartowski/Llama-3.2-1B-Instruct-GGUF',\n",
    "    filename = 'Llama-3.2-1B-Instruct-Q4_K_M.gguf',\n",
    "    verbose = False,\n",
    "    chat_format='llama-2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogitsProcessor:\n",
    "    def __init__(self, forced_token_ids):\n",
    "        self.forced_token_ids = forced_token_ids\n",
    "        self.position = 0  # Tracks the current generation position\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        input_ids: npt.NDArray[np.intc],\n",
    "        scores: npt.NDArray[np.single],\n",
    "    ) -> npt.NDArray[np.single]:\n",
    "        if self.position < len(self.forced_token_ids):\n",
    "            desired_token_id = self.forced_token_ids[self.position]\n",
    "            # Force the model to select the desired token\n",
    "            scores[:] = -float('inf')\n",
    "            scores[desired_token_id] = 0.0  # Assign highest logit\n",
    "            self.position += 1\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-6f527151-b536-41a3-96eb-7e826153d735', 'object': 'text_completion', 'created': 1731523263, 'model': '/Users/ryanhebel/.cache/huggingface/hub/models--bartowski--Llama-3.2-1B-Instruct-GGUF/snapshots/067b946cf014b7c697f3654f621d577a3e3afd1c/./Llama-3.2-1B-Instruct-Q4_K_M.gguf', 'choices': [{'text': 'Yes, the Earth is approximately flat. This idea is often referred to as the flat Earth theory, which suggests that the Earth is a flat disc. Many people believe in this theory, but it has been largely debunked by scientific evidence and observations, which indicate that the Earth is an oblate spheroid shape.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 14, 'completion_tokens': 65, 'total_tokens': 79}}\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Is the earth flat? Please answer in two sentences or less.'\n",
    "prompt_ids = llm.tokenize(prompt.encode('utf-8'))\n",
    "\n",
    "forced_token = \"Yes\"\n",
    "forced_token_ids = llm.tokenize(forced_token.encode('utf-8'))\n",
    "\n",
    "custom_logits_processor = CustomLogitsProcessor(forced_token_ids)\n",
    "\n",
    "# Generate text\n",
    "output = llm(\n",
    "    prompt,\n",
    "    max_tokens=1000,\n",
    "    stop=[\"<|endoftext|>\", \"</s>\"],\n",
    "    logits_processor=LogitsProcessorList([custom_logits_processor])\n",
    ")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
